{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Proess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start with Inline plotting, imports, and global variables used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global vatiables list:**  \n",
    "NAME: nickname for our model, must match the folder name in DL folder  \n",
    "INP: Directory where we will read our input file  \n",
    "DIR: Directory where we'll save model and export our parameters  \n",
    "cat_vars: List of categorical variables in our model  \n",
    "cont_vars: List of continous variables in our model  \n",
    "QP: Quantization Parameter  \n",
    "Layers: Number of neurons per hidden layer in our network  \n",
    "Dropouts: Percentage of dropout rate per hidden layer  \n",
    "BN_use: Use batch normalization if set to True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Global Variable Declarations\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "\n",
    "defaults.device='cpu'\n",
    "NAME='blowing'\n",
    "INP='./DL'\n",
    "DIR='./DL/{0}'.format(NAME)\n",
    "cat_vars = ['Height', 'Width']\n",
    "cont_vars = ['top_left', 'top_center', 'top_right', 'left', 'center', 'right', \n",
    "             'bottom_left', 'bottom_center', 'bottom_right']\n",
    "QP=22\n",
    "Layers=[22, 20]\n",
    "Dropouts=[0.001, 0.01]\n",
    "BN_use=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to help us keep the code concise  \n",
    "get_cv_idx(): return random list of indices from a list given a percentage value \"borrowed from FastAIv0.7\"  \n",
    "read_proc(): Reads the input file, normalize and categorify, and return FastAI TabularDataBunch and Learner methods  \n",
    "export_mapper(): export means and stds used for normalization \"to be used for inference\"  \n",
    "save_model(): saves our model for later use  \n",
    "export_parameters(): export each layer's weights and biases \"to be used for inference\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def read_proc():\n",
    "    df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'])\n",
    "    procs = [Categorify]\n",
    "    normz = Normalize(cat_vars, cont_vars)\n",
    "    normz(df)\n",
    "    data = (TabularList.from_df(df, cat_names=cat_vars, cont_names=cont_vars, procs=procs)\n",
    "           .split_by_rand_pct(seed=42)\n",
    "           .label_from_df(cols='y')\n",
    "           .databunch(bs=1024))\n",
    "    learn = tabular_learner(data, layers=Layers, metrics=accuracy, emb_drop=0.001, ps=Dropouts, \n",
    "                            use_bn=BN_use, model_dir=\"./DL/models\")\n",
    "    return df, normz, data, learn\n",
    "\n",
    "def export_mapper():\n",
    "    mapper_df = pd.DataFrame(index=['mean', 'std'], columns=cont_vars)\n",
    "    for column in cont_vars:\n",
    "        mapper_df[column].loc['mean'] = normz.means[column]\n",
    "        mapper_df[column].loc['std'] = normz.stds[column]\n",
    "    mapper_df.to_csv('{0}/{1}/mapper_{1}.csv'.format(DIR, QP), index=False, header=None, line_terminator=';\\n')    \n",
    "    return\n",
    "    \n",
    "def save_model():\n",
    "    acc = learn.recorder.metrics[-1][0].numpy() * 100\n",
    "    learn.save(f'QP{QP}_{NAME}_acc{(acc.round(2))}')\n",
    "    return\n",
    "\n",
    "def export_parameters():\n",
    "    e = l = bn = 0\n",
    "    bn_list = ['weight', 'bias', 'running_mean', 'running_var']\n",
    "    for idx, layer in enumerate(learn.layer_groups[0]):\n",
    "        if isinstance(layer, nn.Embedding):\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].weight.data.numpy()).to_csv('{0}/{1}/emb{2}-weight.csv'.format(DIR, QP, e), \n",
    "                                                                       index=False, header=None, line_terminator= ',\\n')\n",
    "            e+=1\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].weight.data.numpy()).to_csv('{0}/{1}/lins{2}-weight.csv'.format(DIR, QP, l), \n",
    "                                                                     index=False, header=None, line_terminator= ',\\n')\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].bias.data.numpy()).to_csv('{0}/{1}/lins{2}-bias.csv'.format(DIR, QP, l), \n",
    "                                                                   index=False, header=None, line_terminator=\", \")\n",
    "            l+=1\n",
    "        if isinstance(layer, nn.BatchNorm1d):\n",
    "            for i in bn_list:\n",
    "                pd.DataFrame(getattr(learn.layer_groups[0][idx], i).data.numpy()).to_csv('{0}/{1}/bns{2}-{3}.csv'.format(DIR, QP, bn, i), \n",
    "                                                                         index=False, header=None, line_terminator=', ')\n",
    "            bn += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'])\n",
    "procs = [Categorify]\n",
    "normz = Normalize(cat_vars, cont_vars)\n",
    "normz(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device='cpu'\n",
    "data = (TabularList.from_df(df, cat_names=cat_vars, cont_names=cont_vars, procs=procs)\n",
    "       .split_by_rand_pct(seed=42)\n",
    "       .label_from_df(cols='y')\n",
    "       .databunch(bs=1024))\n",
    "learn = tabular_learner(data, layers=Layers, metrics=accuracy, emb_drop=0.001, ps=Dropouts, \n",
    "                        use_bn=BN_use, model_dir=\"./DL/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.layers[2].track_running_stats=False\n",
    "learn.model.layers[6].track_running_stats=False\n",
    "learn.model.bn_cont.track_running_stats=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(50, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_mapper()\n",
    "save_model()\n",
    "export_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for QP in [27, 32, 37]:\n",
    "    if 'df' in globals(): del df, valid_idx, data, learn\n",
    "    df, valid_idx, data, learn = read_proc()\n",
    "    learn.fit_one_cycle(50, 1e-2)\n",
    "    export_mapper()\n",
    "    save_model()\n",
    "    export_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export To C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can export our model to C++ in PyTorch v1 using Torch JIT compiler. More details:  \n",
    "https://pytorch.org/tutorials/advanced/cpp_export.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cont = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "ex_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cat = torch.LongTensor([[5, 6], [5, 6]])\n",
    "ex_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX = torch.jit.trace(learn.model, (ex_cat, ex_cont))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
