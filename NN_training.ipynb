{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Proess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports & Global variables list:**  \n",
    "A symbolic link is done to import FastAI v0.7 library, the target folder is named \"fastai07\"  \n",
    "\n",
    "NAME: nickname for our model, must match the folder name in DL folder  \n",
    "INP: Directory where we will read our input file  \n",
    "DIR: Directory where we'll save model and export our parameters  \n",
    "cat_vars: List of categorical variables in our model  \n",
    "cont_vars: List of continous variables in our model  \n",
    "QP: Quantization Parameter  \n",
    "Layers: Number of neurons per hidden layer in our network  \n",
    "Dropouts: Percentage of dropout rate per hidden layer  \n",
    "BN_use: Use batch normalization if set to True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai07.structured import *\n",
    "from fastai07.column_data import *\n",
    "\n",
    "NAME='blowing'\n",
    "INP='./DL'\n",
    "DIR='./DL/{0}'.format(NAME)\n",
    "cat_vars = ['Height', 'Width']\n",
    "cont_vars = ['top_left', 'top_center', 'top_right', 'left', 'center', 'right', \n",
    "             'bottom_left', 'bottom_center', 'bottom_right']\n",
    "maplist = [['top_left', 0], ['top_center', 1], ['top_right', 2], ['left', 3], ['center', 4], ['right', 5], \n",
    "         ['bottom_left', 6], ['bottom_center', 7], ['bottom_right', 8]]\n",
    "QP=22\n",
    "Layers=[22, 20]\n",
    "Dropouts=[0.001, 0.01]\n",
    "BN_use=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**:  \n",
    "In FastAI v0.7, there's a proc_df() function that does the following:  \n",
    "1) Splits dependent variable \"output\" from the dataframe  \n",
    "2) Normalizes the continuous variables  \n",
    "3) Returns a mapper that holds the mean and std for normalization  \n",
    "4) Categorizes the categorical variables  \n",
    "5) Handles missing values  \n",
    "\n",
    "This function will be used in read_proc() process our data. Note that we don't have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, normalize, and process Inputs and Outputs\n",
    "def read_proc():\n",
    "    df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'], nrows=200)\n",
    "    for v in cat_vars: df[v] = df[v].astype('category').cat.as_ordered()\n",
    "    for v in cont_vars: df[v] = df[v].astype('float32')\n",
    "    df, y, nas, mapper = proc_df(df, 'y',do_scale=True)\n",
    "    del nas\n",
    "    for v in cat_vars: df[v] = df[v].astype('category').cat.as_ordered()\n",
    "    for v in cont_vars: df[v] = df[v].astype('float32')\n",
    "    cat_sz = [(c, len(df[c].cat.categories)+1) for c in cat_vars]\n",
    "    # Rule of Thumb for embedding sizes \"taken from FastAI course 2018\"\n",
    "    emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "    val_idx = get_cv_idxs(len(df), val_pct=0.2)\n",
    "    return df, y, mapper, emb_szs, val_idx\n",
    "\n",
    "# Export the Mean and STDev\n",
    "# The target folder is: ./$DIR/$QP/\n",
    "def export_mapper():\n",
    "    mapper_df = pd.DataFrame(index=['mean', 'std'], columns=cont_vars)\n",
    "    for column,i in maplist:\n",
    "        mapper_df[column].loc['mean'] = np.float64(mapper.features[i][1].mean_)\n",
    "        mapper_df[column].loc['std'] = np.float64(np.sqrt(mapper.features[i][1].var_))\n",
    "\n",
    "    mapper_df.to_csv('{0}/{1}/mapper_{1}.csv'.format(DIR, QP), index=False, header=None, line_terminator=\";\\n\")\n",
    "    return\n",
    "\n",
    "# Process and Save model\n",
    "# The saved model is in the format: QP{qp}_{name}_{accuracy}\n",
    "def save_model():\n",
    "    log_preds, targs = m.predict_with_targs()\n",
    "    preds = np.argmax(log_preds, axis=1)\n",
    "    right = 0\n",
    "    for i in range (len(preds)):\n",
    "        if(preds[i] == targs[i]):\n",
    "            right += 1\n",
    "    acc = (right / len(preds)) * 100\n",
    "    print(\"Validation accuracy: \", acc)\n",
    "    name = \"QP{0}_{1}_acc{2}\".format(QP, NAME, round(acc, 2))\n",
    "    m.save(name)\n",
    "    return\n",
    "\n",
    "# Export Weights and Biases for each layer\n",
    "# The target folder is: ./$DIR/$QP/\n",
    "def export_parameters():\n",
    "    for i in range(len(m.model.bns)):\n",
    "        pd.DataFrame(m.model.bns[i].weight.data.numpy()).to_csv('{0}/{1}/bns{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                index=False, header=None , line_terminator=\", \")\n",
    "        pd.DataFrame(m.model.bns[i].bias.data.numpy()).to_csv('{0}/{1}/bns{2}-bias.csv'.format(DIR, QP, i), \n",
    "                                                              index=False, header=None , line_terminator=\", \")\n",
    "    for i in range(len(m.model.lins)):\n",
    "        pd.DataFrame(m.model.lins[i].weight.data.numpy()).to_csv('{0}/{1}/lins{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                 index=False, header=None, line_terminator=\",\\n\")\n",
    "        pd.DataFrame(m.model.lins[i].bias.data.numpy()).to_csv('{0}/{1}/lins{2}-bias.csv'.format(DIR, QP, i), \n",
    "                                                               index=False, header=None, line_terminator=\", \")\n",
    "    for i in range(len(m.model.embs)):\n",
    "        pd.DataFrame(m.model.embs[i].weight.data.numpy()).to_csv('{0}/{1}/emb{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                index=False, header=None, line_terminator=\",\\n\")\n",
    "    pd.DataFrame(m.model.outp.weight.data.numpy()).to_csv('{0}/{1}/outp-weight.csv'.format(DIR, QP), \n",
    "                                                          index=False, header=None, line_terminator=\",\\n\")\n",
    "    pd.DataFrame(m.model.outp.bias.data.numpy()).to_csv('{0}/{1}/outp-bias.csv'.format(DIR, QP), index=False, \n",
    "                                                        header=None, line_terminator=\", \")\n",
    "    pd.DataFrame(m.model.bn.weight.data.numpy()).to_csv('{0}/{1}/bn-weight.csv'.format(DIR, QP), index=False, \n",
    "                                                        header=None, line_terminator=\", \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read and process our input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in globals(): del df, y, mapper\n",
    "df, y, mapper, emb_szs, val_idx = read_proc()\n",
    "# Optional: export mapper for inference\n",
    "# export_mapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ModelData and Learner objects  \n",
    "The problem we're dealing with is a multi-class classification \"output is one of 49 fractional locations\", so in get_learner() function, we set is_multi= and is_reg= to False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(INP, val_idx, df, y, cat_flds=cat_vars, \n",
    "                                       bs=1024, is_multi=False, is_reg=False)\n",
    "m = md.get_learner(emb_szs, len(df.columns) - len(cat_vars),\n",
    "                   0.001, 49, Layers, Dropouts, use_bn=BN_use)\n",
    "# Optional: Load previously saved model\n",
    "# m.load('QP22_blowing_200_train_acc36.51')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run learning Rate Finder:  \n",
    "Plots the error for each learning rate, we choose the learning rate before the error starts flattening out \"in our case, usually learning rate = 1e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lr_find()\n",
    "m.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for a specified number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LR = 3e-3\n",
    "m.fit(LR, 200, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and Export parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()\n",
    "export_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for other Quantization Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for QP in [27, 32, 37]:\n",
    "    if 'df' in globals(): del df, y, mapper\n",
    "    df, y, mapper, emb_szs, val_idx = read_proc()\n",
    "    export_mapper()\n",
    "    md = ColumnarModelData.from_data_frame(INP, val_idx, df, y, cat_flds=cat_vars, \n",
    "                                           bs=1024, is_multi=False, is_reg=False)\n",
    "    m = md.get_learner(emb_szs, len(df.columns) - len(cat_vars),\n",
    "                       0.001, 49, Layers, Dropouts, use_bn=BN_use)\n",
    "    m.fit(LR, 200, metrics=[accuracy])\n",
    "    save_model()\n",
    "    export_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
