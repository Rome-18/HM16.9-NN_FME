{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Proess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start with Inline plotting, imports, and global variables used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global vatiables list:**  \n",
    "NAME: nickname for our model, must match the folder name in DL folder  \n",
    "INP: Directory where we will read our input file  \n",
    "DIR: Directory where we'll save model and export our parameters  \n",
    "cat_vars: List of categorical variables in our model  \n",
    "cont_vars: List of continous variables in our model  \n",
    "QP: Quantization Parameter  \n",
    "Layers: Number of neurons per hidden layer in our network  \n",
    "Dropouts: Percentage of dropout rate per hidden layer  \n",
    "BN_use: Use batch normalization if set to True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Global Variable Declarations\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "\n",
    "defaults.device='cuda'\n",
    "NAME='blowing'\n",
    "INP='./DL'\n",
    "DIR='./DL/{0}'.format(NAME)\n",
    "cat_vars = ['Height', 'Width']\n",
    "cont_vars = ['top_left', 'top_center', 'top_right', 'left', 'center', 'right', \n",
    "             'bottom_left', 'bottom_center', 'bottom_right']\n",
    "QP=22\n",
    "Layers=[22, 20]\n",
    "Dropouts=[0.001, 0.01]\n",
    "BN_use=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to help us keep the code concise  \n",
    "get_cv_idx(): return random list of indices from a list given a percentage value \"borrowed from FastAIv0.7\"  \n",
    "read_proc(): Reads the input file, normalize and categorify, and return FastAI TabularDataBunch and Learner methods  \n",
    "export_mapper(): export means and stds used for normalization \"to be used for inference\"  \n",
    "save_model(): saves our model for later use  \n",
    "export_parameters(): export each layer's weights and biases \"to be used for inference\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def read_proc():\n",
    "    df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'])\n",
    "    procs = [Categorify]\n",
    "    normz = Normalize(cat_vars, cont_vars)\n",
    "    normz(df)\n",
    "    data = (TabularList.from_df(df, cat_names=cat_vars, cont_names=cont_vars, procs=procs)\n",
    "           .split_by_rand_pct(seed=42)\n",
    "           .label_from_df(cols='y')\n",
    "           .databunch(bs=1024))\n",
    "    learn = tabular_learner(data, layers=Layers, metrics=accuracy, emb_drop=0.001, ps=Dropouts, \n",
    "                            use_bn=BN_use, model_dir=\"./DL/models\")\n",
    "    return df, normz, data, learn\n",
    "\n",
    "def export_mapper():\n",
    "    mapper_df = pd.DataFrame(index=['mean', 'std'], columns=cont_vars)\n",
    "    for column in cont_vars:\n",
    "        mapper_df[column].loc['mean'] = normz.means[column]\n",
    "        mapper_df[column].loc['std'] = normz.stds[column]\n",
    "    mapper_df.to_csv('{0}/{1}/mapper_{1}.csv'.format(DIR, QP), index=False, \n",
    "                     header=None, line_terminator=';\\n')    \n",
    "    return\n",
    "    \n",
    "def save_model():\n",
    "    acc = learn.recorder.metrics[-1][0].numpy() * 100\n",
    "    learn.save(f'QP{QP}_{NAME}_acc{(acc.round(2))}')\n",
    "    return\n",
    "\n",
    "def export_parameters():\n",
    "    e = l = bn = 0\n",
    "    bn_list = ['weight', 'bias', 'running_mean', 'running_var']\n",
    "    for idx, layer in enumerate(learn.layer_groups[0]):\n",
    "        if isinstance(layer, nn.Embedding):\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].weight.data.cpu().numpy()).to_csv(\n",
    "                '{0}/{1}/emb{2}-weight.csv'.format(DIR, QP, e), index=False, \n",
    "                header=None, line_terminator= ',\\n')\n",
    "            e+=1\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].weight.data.cpu().numpy()).to_csv(\n",
    "                '{0}/{1}/lins{2}-weight.csv'.format(DIR, QP, l), index=False, \n",
    "                header=None, line_terminator= ',\\n')\n",
    "            pd.DataFrame(learn.layer_groups[0][idx].bias.data.cpu().numpy()).to_csv(\n",
    "                '{0}/{1}/lins{2}-bias.csv'.format(DIR, QP, l), index=False, \n",
    "                header=None, line_terminator=\", \")\n",
    "            l+=1\n",
    "        if isinstance(layer, nn.BatchNorm1d):\n",
    "            for i in bn_list:\n",
    "                pd.DataFrame(getattr(learn.layer_groups[0][idx], i).data.cpu().numpy()).to_csv(\n",
    "                    '{0}/{1}/bns{2}-{3}.csv'.format(DIR, QP, bn, i), index=False, \n",
    "                    header=None, line_terminator=', ')\n",
    "            bn += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'], nrows=501688)\n",
    "procs = [Categorify]\n",
    "normz = Normalize(cat_vars, cont_vars)\n",
    "normz(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device='cuda'\n",
    "data = (TabularList.from_df(df, cat_names=cat_vars, cont_names=cont_vars, procs=procs)\n",
    "#        .split_by_rand_pct(seed=42)\n",
    "        .split_by_idx(list(range(len(df)-round(len(df)*0.2), len(df))))\n",
    "       .label_from_df(cols='y')\n",
    "       .databunch(bs=2048))\n",
    "# data.train_dl = data.train_dl.new(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=Layers, metrics=accuracy, emb_drop=0.001, ps=Dropouts, \n",
    "                        use_bn=BN_use, model_dir=\"./DL/models\")\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.layers[2].momentum=1\n",
    "learn.model.layers[6].momentum=1\n",
    "learn.model.bn_cont.momentum=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('FP16-BS2k-M1-Acc34.94-L2.18');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('FP16-BS2k-M1-Acc34.27-L2.214')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(9, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('FP16-BS2k-M1-Acc34.9-L2.18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(8, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('FP16-BS2k-M1-Acc34.94-L2.18');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_mapper()\n",
    "save_model()\n",
    "export_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for QP in [27, 32, 37]:\n",
    "    if 'df' in globals(): del df, valid_idx, data, learn\n",
    "    df, valid_idx, data, learn = read_proc()\n",
    "    learn.fit_one_cycle(50, 1e-2)\n",
    "    export_mapper()\n",
    "    save_model()\n",
    "    export_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper=pd.read_csv('./DL/mapper_22.csv', names=cont_vars)\n",
    "test = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'], nrows=1e5)\n",
    "for i in cont_vars:\n",
    "    test[i]=(test[i]-mapper.iloc[0][i]) / mapper.iloc[1][i]\n",
    "learn.data.add_test(TabularList.from_df(test, cat_names=cat_vars, cont_names=cont_vars, procs=procs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('FP16-BS2k-M1-Acc34.94-L2.18');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.embeds[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export To C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can export our model to C++ in PyTorch v1 using Torch JIT compiler. More details:  \n",
    "https://pytorch.org/tutorials/advanced/cpp_export.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('FP16-BS2k-M1-Acc34.94-L2.18', device='cpu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.cpu()  # Transfer model to CPU - can't export model to C++ due to HalfTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.layers[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cont = torch.cuda.HalfTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "ex_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cat = torch.cuda.LongTensor([[5, 6], [5, 6]])\n",
    "ex_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX = torch.jit.trace(learn.model, (ex_cat, ex_cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = torch.cuda.LongTensor([[7,7], [7,6]])\n",
    "cont = torch.cuda.HalfTensor(\n",
    "    [[3.071918, 1.946268, 1.806007, 1.771071, 2.639419, 3.387859, 3.766593, 6.594494, 4.977126],\n",
    "     [2.073078, 1.368932, 1.566441, 0.901851, 1.519509, 2.410473, 2.532072, 4.585548, 3.595045]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[0].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outpt = XXX(cat[0].unsqueeze(0), cont[0].unsqueeze(0))    # Only one Sample! Has to be unsqueezed(0) first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outpt = XXX(cat, cont)    # Batch \"at least 2 samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,i = outpt.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX.save('FP16-model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
